{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation and Inference, and Hypothesis Testing\n",
    "## Estimation and Inference\n",
    "- estimate is just going to give us an estimate of a certain parameter, such as the mean from our sample data.\n",
    "- When performing statistical inference, we're trying to understand the underlying distribution of the population, including our estimates of the mean, as well as other parameters such as the standard error of the underlying properties of the population that we're sampling from\n",
    "\n",
    "## Machine Learning and Statistical Inference\n",
    "Machine learning and statistical inference are similar\n",
    "\n",
    "(a case of computer science borrowing from a long history in statistics).\n",
    "\n",
    "In both cases, we're using data to learn/infer qualities of a distribution that generated the data\n",
    "(often termed the data -generating process).\n",
    "\n",
    "We may care either about the whole distribution or just features (e.g. mean).\n",
    "\n",
    "Machine learning applications that focus on understanding parameters and individual effects\n",
    "involve more tools from statistical inference (some applications are focused only on results).\n",
    "\n",
    "## Parametric versus Non-parametric. \n",
    "A statistical inference is about finding the underlying data generating process of our data, then the statistical model is going to be a set of the possible distributions or even reggressions that that data can take\n",
    "\n",
    "parametric model is a particular type of statistical model. What differentiates a parametric model? Some of the major characteristics, or that a parametric model is constrained to a finite number of parameters, and that'll rely on some strict assumptions made about the distributions from which that data is pulled.\n",
    "\n",
    "non-parametric models, will mean that our inference will not rely on as many assumptions, such as it will not have to rely on the data being pulled from a particular distribution, it'll be a distribution free inference.\n",
    "\n",
    "## common distributions\n",
    "- Uniform distribution\n",
    "- Normal/Gaussian distribution\n",
    "- Log-normal distribution => log transformation => normal distribution\n",
    "- exponential curve\n",
    "- poison distribution\n",
    "\n",
    "## Bayesian and frequentist statistics\n",
    "- Frequentist statistics is concerned with repeated observations to the limit\n",
    "- processes may have true frequencies in their real population mean or whatever it is. But we're interested in modeling probabilities as many, many repeats of an experiment\n",
    "\n",
    "## Frequentist vs. Bayesian: Bayesian\n",
    "A Bayesian describes parameters by probability distributions.\n",
    "\n",
    "Before seeing any data, a prior distribution (based on the experimenters' belief) is formulated.\n",
    "\n",
    "This prior distribution is then updated after seeing data (a sample from the distribution).\n",
    "\n",
    "After updating, the distribution is called the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Hypothesis Testing\n",
    "A hypothesis is a statement about a population parameter.\n",
    "\n",
    "We create two hypotheses:\n",
    "- The null hypothesis (Ho)\n",
    "- The alternative hypothesis (H1, or HA)\n",
    "\n",
    "We decide which one to call the null depending on how the problem is set up.\n",
    "\n",
    "A hypothesis testing procedure gives us a rule to decide:\n",
    "- For which values of the test statistic do we accept Ho\n",
    "- For which values of the test statistic do we reject Ho, and accept H1,\n",
    "\n",
    "### Type 1 vs Type 2 Error\n",
    "\n",
    "- A type I error (false-positive) occurs if an investigator rejects a null hypothesis that is actually true in the population; \n",
    "- A type II error (false-negative) occurs if the investigator fails to reject a null hypothesis that is actually false in the population.\n",
    "\n",
    "### Hypothesis Testing Terminology\n",
    "\n",
    "- The likelihood ratio is called a test statistic: we use it to decide whether to accept/reject Ho-\n",
    "- The rejection region: is the set of values of the test statistic that lead to rejection of Ho-\n",
    "- The acceptance region: is the set of values of the test statistic that lead to acceptance of Ho-\n",
    "- The null distribution: is test statistic's distribution when the null is true.\n",
    "\n",
    "Hypothesis Testing: Marketing Intervention\n",
    "\n",
    "Testing marketing intervention effectiveness:\n",
    "- For a new direct mail marketing campaign to existing customers, the null\n",
    "hypothesis (Ho), suggests the campaign does not impact purchasing.\n",
    "- The alternative hypothesis (H,), suggests it has an impact.\n",
    "\n",
    "Hypothesis Testing: Product Quality/Size\n",
    "\n",
    "Testing whether a product meets expected size threshold:\n",
    "- Suppose a product is produced in various factories, with expected size S\n",
    "- To confirm that the product size meets the standard within a margin of error, the\n",
    "company might:\n",
    "- randomly sample from each production source,\n",
    "- establish Ho (product size is not significantly different from S),\n",
    "- and H, (there is a significant deviation in product size),\n",
    "- test whether Ho can be rejected in favor of H1, based on the observed mean\n",
    "and standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance Level and P-Values\n",
    "\n",
    "Significance Level and P-Values\n",
    "- A significance level (α) is a probability threshold below which the null hypothesis\n",
    "will be rejected.\n",
    "- We must choose an a before computing the test statistic!\n",
    "- If we don't, we might be accused of p-hacking.\n",
    "- Choosing α is somewhat arbitrary, but often .01 or .05.\n",
    "\n",
    "Important terminology:\n",
    "- The p-value: smallest significance level at which the null hypothesis would be rejected.\n",
    "- The confidence interval: the values of the statistic for which we accept the null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F Statistic\n",
    "\n",
    "Power: Bonferroni Correction\n",
    "- The Bonferroni Correction: says \"choose threshold\n",
    "SO that the probability of making a Type\n",
    "error (assuming no effect) is 5%\".\n",
    "\n",
    "Typically choose:\n",
    "- threshold = 0.05 / (# tests)\n",
    "- Bonferroni Correction allows the probability of a Type I error to be controlled,\n",
    "but at the cost of power.\n",
    "- Effects either need to be larger or the tests need larger samples, to be detected.\n",
    "- Best practice is to limit the number of comparisons done to a few well-motivated cases."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
