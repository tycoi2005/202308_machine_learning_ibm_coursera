# Basic Knowledge

In order to be successful in this course, you will need a working knowledge of the following:

Familiarity with programming on a Python development environment

Familiarity with Jupyter notebooks

Fundamental understanding of Calculus, Linear Algebra, Probability, and Statistics

# Computing Environment
Throughout this course we will be providing Jupyter notebooks (
https://jupyter.org/
) for you to download and run on your local computer.  In some cases they will be in the form of a lab you will complete or as a follow-along notebook that you can complete with the video demo.

# Introduction to Artificial Intelligence and Machine Learning
AI > ML > Deep Learning

AI :

    a branch of computer science dealing with the simulation of intelligent behavior in computers

    Colloquially, the term artificial intelligence is applied when a machine mimics cognitive functions that humans associate with other human minds, such as learning and problem solving

    a program that can sense, reason, act and adapt

ML :

    algorithms whose performance improve as they are exposed to more data over time

    It's going to be a subset that's going to learn from observing data.

    The more data, the better the algorithm is able to learn the underlying patterns.

    supervised learning: email spam -> make predictions -> ex: fraud detection

    unsupervised leaning: not have a target column -> find structure in data -> customer segmentation

DL:

    subset of ML in which multilayered neural networks learn from vast amount of data

# Modern AI: Applications and the Machine Learning Workflow

Computer Vision

    self driving car

    health care

Natural language processing

    language translator

Base of Cutting Edge results:

    Bigger Datasets

    Faster Computers

    Neural Nets

Apps:

    Distance, Map

    Ride sharing

    Social networking

        Content relevant identifying, sugessting

        Image recognition, sentiment analysis

    Personal Asssitant

    Object detection

Background and tool:

    Python

         Numpy for numerical analysis,

         Pandas for which we're going to actually read in our data into Pandas DataFrames,

         Matplotlib and Seaborn for visualization,

         Scikit-Learn for machine learning

         TensorFlow and Keras for deep-learning specifically.

    Basic statistics including probability, caculating moments, Bayes' Rule

        Moments:

            First moment (Mean) – Mean is the most commonly used measure of central tendency. It gives us an idea of where the data is centered in a distribution.

            Second moment (Variance) – Variance measures how to spread out or dispersed the data is around its mean value.

            Third moment (Skewness) – Skewness measures the asymmetry of a distribution; it tells us if there are more values on one side than another side of the distribution (positively skewed, negatively skewed, or symmetric). A positive value of skew represents right-skewed distributions, a negative value of skew represents left-skewed distributions and a zero value of skewness indicates that the distribution is symmetric. The following picture demonstrates positive, negative, and zero-skewed datasets.

            Fourth moment (Kurtosis) – Kurtosis measures the peakedness or flatness of a distribution; it tells us how much weight is at the center and tail ends of the distribution (leptokurtic, platykurtic, or mesokurtic). Positive kurtosis indicates that the data is more concentrated near the mean than in a normal distribution, while negative kurtosis indicates that the data is spread out more than in a normal distribution. The following picture demonstrates leptokurtic, platykurtic, and mesokurtic datasets.

Machine learning workflow

    Problem statement: What problem are you trying to solve?

    Data Collection: What data you need to solve it?

    Data Exploration and Preprocessing: How should you clean your data so your model can use it?

    Modeling: Build a model to solve our problem?

    Validation: Did I solve the problem?

    Decision Making and Deployment: Communicate to stakeholders or put into production

Vocabolary:

    target variable

    features/ explanatory variables: Those will be the other columns besides the target variable that you will use in order to predict your target variable

    observation/example : one line of dataset, one row

    label: value of target variable, one data point
