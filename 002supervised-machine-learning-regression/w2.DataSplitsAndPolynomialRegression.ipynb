{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splits and Polynomial Regression\n",
    "\n",
    "There are a few best practices to avoid overfitting of your regression models. One of these best practices is splitting your data into training and test sets. Another alternative is to use cross validation. And a third alternative is to introduce polynomial features. This module walks you through the theoretical framework and a few hands-on examples of these best practices.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "Realize the importance of having a test set to avoid overfitting\n",
    "\n",
    "Practice using the train_split function to split your data into training and testing sets\n",
    "\n",
    "Recognize the trade off between model complexity and prediction error\n",
    "\n",
    "Assess whether introducing polynomial features improves the error metrics of your linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Splits\n",
    "\n",
    "### Learning Goals\n",
    "\n",
    "In this section, we will cover:\n",
    "- Splitting data into training and testing samples\n",
    "- Cross-validation approaches\n",
    "- Model complexity vs. error\n",
    "\n",
    "![Fiting Training and Test Data](./images/07_FittingTrainingAndTestData.jpg \"Fitting Training and Test Data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import the train and test split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data and put 30% into the test set\n",
    "train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "# Other method for splitting data\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class sklearn.preprocessing.StandardScaler(*, copy=True, with_mean=True, with_std=True)[source]\n",
    "\n",
    "Standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "The standard score of a sample x is calculated as:\n",
    "\n",
    "z = (x - u) / s\n",
    "\n",
    "where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### class sklearn.preprocessing.MinMaxScaler(feature_range=(0, 1), *, copy=True, clip=False)[source]\n",
    "\n",
    "Transform features by scaling each feature to a given range.\n",
    "\n",
    "This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.\n",
    "\n",
    "The transformation is given by:\n",
    "\n",
    "```python\n",
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_scaled = X_std * (max - min) + min\n",
    "where min, max = feature_range.\n",
    "```\n",
    "\n",
    "This transformation is often used as an alternative to zero mean, unit variance scaling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class sklearn.preprocessing.MaxAbsScaler(*, copy=True)[source]Â¶\n",
    "\n",
    "Scale each feature by its maximum absolute value.\n",
    "\n",
    "This estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
