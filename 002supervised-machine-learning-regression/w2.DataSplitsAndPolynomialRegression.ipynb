{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splits and Polynomial Regression\n",
    "\n",
    "There are a few best practices to avoid overfitting of your regression models. One of these best practices is splitting your data into training and test sets. Another alternative is to use cross validation. And a third alternative is to introduce polynomial features. This module walks you through the theoretical framework and a few hands-on examples of these best practices.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "Realize the importance of having a test set to avoid overfitting\n",
    "\n",
    "Practice using the train_split function to split your data into training and testing sets\n",
    "\n",
    "Recognize the trade off between model complexity and prediction error\n",
    "\n",
    "Assess whether introducing polynomial features improves the error metrics of your linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Splits\n",
    "\n",
    "### Learning Goals\n",
    "\n",
    "In this section, we will cover:\n",
    "- Splitting data into training and testing samples\n",
    "- Cross-validation approaches\n",
    "- Model complexity vs. error\n",
    "\n",
    "![Fiting Training and Test Data](./images/07_FittingTrainingAndTestData.jpg \"Fitting Training and Test Data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import the train and test split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data and put 30% into the test set\n",
    "train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "# Other method for splitting data\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class sklearn.preprocessing.StandardScaler(*, copy=True, with_mean=True, with_std=True)[source]\n",
    "\n",
    "Standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "The standard score of a sample x is calculated as:\n",
    "\n",
    "z = (x - u) / s\n",
    "\n",
    "where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### class sklearn.preprocessing.MinMaxScaler(feature_range=(0, 1), *, copy=True, clip=False)[source]\n",
    "\n",
    "Transform features by scaling each feature to a given range.\n",
    "\n",
    "This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.\n",
    "\n",
    "The transformation is given by:\n",
    "\n",
    "```python\n",
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_scaled = X_std * (max - min) + min\n",
    "where min, max = feature_range.\n",
    "```\n",
    "\n",
    "This transformation is often used as an alternative to zero mean, unit variance scaling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class sklearn.preprocessing.MaxAbsScaler(*, copy=True)[source]Â¶\n",
    "\n",
    "Scale each feature by its maximum absolute value.\n",
    "\n",
    "This estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "\n",
    "### Learning Goals\n",
    "\n",
    "In this section, we will cover:\n",
    "- Extending linear regression\n",
    "- Using polynomial features to capture nonlinear effects\n",
    "- Other models that can be used for regression and\n",
    "classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition of Polynomial Features\n",
    "\n",
    "Capture higher order features of data\n",
    "by adding polynomial features.\n",
    "\n",
    "\"Linear regression\" means\n",
    "linear combinations of features\n",
    "\n",
    "$ y_\\beta (x) =  \\beta_0 + \\beta_1x +\\beta_2x^2+\\beta_3x^3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also include variable interactions:\n",
    "\n",
    "$y_\\beta(x) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_1x_2$\n",
    "\n",
    "How is the correct functional form chosen?\n",
    "- Check relationship of each variable or with outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancing the Linear Model\n",
    "\n",
    "Adjusting the standard linear approach to regression by adding polynomial features\n",
    "is one of many approaches to dealing with the fundamental problems:\n",
    "- prediction\n",
    "- interpretation\n",
    "\n",
    "As we move into model evaluation, keep in mind that the same tools are useful for\n",
    "evaluating a wide variety of regression and classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to Polynomial features, we will also examine several additional variants\n",
    "of standard models, using many for both regression and classification.\n",
    "\n",
    "Some examples include:\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbors\n",
    "- Decision Trees\n",
    "- Support Vector Machines\n",
    "- Random Forests\n",
    "- Ensemble Methods\n",
    "- Deep Learning Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features: The Syntax\n",
    "\n",
    "Import the class containing the transformation method\n",
    "```python\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "```\n",
    "\n",
    "Create an instance of the class\n",
    "```python\n",
    "polyFeat = PolynomialFeatures(degree=2\n",
    "```\n",
    "\n",
    "Create the polynomial features and then transform the data\n",
    "```python\n",
    "polyFeat = polyFeat.fit(X_data)\n",
    "X_poly = polyFeat.transform(X_data)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
