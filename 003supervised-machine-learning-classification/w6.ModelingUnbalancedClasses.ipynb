{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Unbalanced Classes\n",
    "\n",
    "Some classification models are better suited than others to outliers, low occurrence of a class, or rare events. The most common methods to add robustness to a classifier are related to stratified sampling to re-balance the training data. This module will walk you through both stratified sampling methods and more novel approaches to model data sets with unbalanced classes. \n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "Identify class weights and sampling as methods to deal with unbalanced classes in a data set.\n",
    "\n",
    "Recognize the syntax for building for sampling, blagging, and nearest neighbor methods for modeling unbalanced classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretability\n",
    "\n",
    "In general, we need explanation methods that can make the behaviors and predictions of machine learning models understandable to humans. We need to use those methods to understand the model structures, what important features should be included in the model, and how those models map features to prediction outcomes.\n",
    "\n",
    "\n",
    "In addition, sometimes knowing how models work exactly may give us more insights than merely predicting the outcomes. For example, understanding how an AI system diagnoses cancer may help human health experts identify evidence-based risk factors. For decision makers, interpretability is important especially for those in very sensitive or high-risk domains such as finance or health. We need to be confident and be able to trust that the model is working correctly. Black-box machine learning systems cannot be trusted unless they can be monitored and interpreted. As such, building trustable models is sometimes even more important than building high-performing models.\n",
    "\n",
    "Understanding machine learning models for:\n",
    "- Model explaination\n",
    "- Model trust\n",
    "- Model debug \n",
    "\n",
    "Recap\n",
    "- We can only trust and effectively debug machine\n",
    "learning models if they are understandable\n",
    "- Self-interpretable models have simple and\n",
    "intuitive structures\n",
    "- Non- self- interpretable models have complex\n",
    "structures and can be described as black-box\n",
    "models\n",
    "\n",
    "### Examples of Self-Interpretable and Non-Self-Interpretable Models\n",
    "\n",
    "#### Self-Interpretable\n",
    "\n",
    "Linear models are probably the most widely used predictive models due to their simplicity and effectiveness, especially in the financial industry. Their structure is simple with just a linear combination of features that predict values. As such, linear model prediction outcomes often require minimal effort to understand.\n",
    "\n",
    "Tree models such as decision trees, are another popular self-interpretable type of model. The main characteristic of tree models is they mimic humanâ€™s reasoning process via creating a set of IF-THEN-ELSE rules. \n",
    "\n",
    "The K-nearest neighbor model, or KNN, can also be considered a self-interpretable model if the feature spaces can be comprehensible and kept small.\n",
    "\n",
    "#### Non-Self-Interpretable Models\n",
    "\n",
    "Ensemble Models\n",
    "\n",
    "![](./images/70_ModelInterpretationMethods.png)\n",
    "\n",
    "\n",
    "\n",
    "### Model-Agnostic Explanations\n",
    "\n",
    "![](./images/71_ModelAgnosticExplainations.png)\n",
    "\n",
    "Feature importance\n",
    "\n",
    "Measure the importance of features\n",
    "\n",
    "1. Simplify your model by only including important features\n",
    "2. Interpret how predictions were made\n",
    "\n",
    "Permutation feature importance\n",
    "- The basic idea of permutation feature importance is very simple. For each feature, we shuffle its feature values and use the model to make predictions based on the shuffled values. In most cases, the prediction error will increase. Permuting important or impactful features will tend to generate large prediction errors and less important features will tend to generate small error increases. As such, feature importance can be measured by calculating the difference between the prediction errors before and after permutation. \n",
    "\n",
    "![](./images/72_PermutationFeatureImportanceExample.png)\n",
    "\n",
    "- Partial Dependency Plot is an effective way to illustrate the relationship between a feature and the model outcome. It essentially visualizes the marginal effects of a feature, that is, it shows how the model outcome changes when a specific feature changes in its distribution. Note that we keep the rest of the features unchanged while changing the interested feature. \n",
    "\n",
    "Impurity-based feature importance\n",
    "\n",
    "Shapley Additive exPlanations (SHAP) values\n",
    "\n",
    "### Surrogate Models\n",
    "\n",
    "![](./images/73_SurogateModels.png)\n",
    "\n",
    "![](./images/74_GlobalSurrogateModels.png)\n",
    "\n",
    "Local surrogate\n",
    "- Global surrogate models may not always work\n",
    "  - Large inconsistency between surrogate models and black-box models\n",
    "  - Multiple data instance groups or clusters in the dataset\n",
    "- Explain specific interested data instances locally\n",
    "- A local surrogate model is built on one or a few instances\n",
    "\n",
    "Local Interpretable Model-Agnostic Explanations (LIME)\n",
    "![](./images/75_LocalInterpretableModel-AgnosticExplanations.png)\n",
    "\n",
    "\n",
    "### Practice Lab: Model Interpretability\n",
    "\n",
    "### Practice: Model interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Unbalanced Classes\n",
    "\n",
    "the classifiers themselves in order to learn the actual parameters and decisions are built to optimize accuracy specifically. They are built to get as many correct as possible no matter the class. And hence, they'll often perform poorly on under represent in classes.\n",
    "\n",
    "Ways to deal with unbalanced Classes\n",
    "\n",
    "- Undersampling (Downsampling) here means only taking as many of the larger class of our majority class, as there are available of our smaller class of our minority class. So you see here we have a lot of the majority class only six of the minority class So we randomly select only six from our majority class, so that we are now working with a balanced dataset.\n",
    "Play video starting at :2:4 and follow transcript2:04\n",
    "\n",
    "- Oversampling (Up sampling) is essentially creating copies of the row of smaller outcome until we have a balanced sample.\n",
    "\n",
    "- Mix Downsampling and Up Sampling\n",
    "\n",
    "\n",
    "### Upsampling and Downsampling\n",
    "\n",
    "Steps for unbalanced datasets:\n",
    "- Do a stratified test-train split\n",
    "- Up or down sample the full dataset\n",
    "- Build models\n",
    "\n",
    "Downsampling\n",
    "\n",
    "- Downsampling adds tremendous importance to the minor class, typically shooting up\n",
    "recall and bringing down precision.\n",
    "\n",
    "- Values like 0.8 recall and 0.15 precision isn't uncommon.\n",
    "\n",
    "Upsampling\n",
    "\n",
    "- Upsampling mitigates some of the excessive weight on the minor class. Recall is still\n",
    "typically higher than precision, but the gap is lesser.\n",
    "\n",
    "- Values like 0.7 recall and 0.4 precision isn't uncommon. And are often considered good\n",
    "results for an unbalanced dataset.\n",
    "\n",
    "![](./images/76_CrossValidation.png)\n",
    "\n",
    "Every classifier used produces a different model.\n",
    "\n",
    "Every dataset we use (produced by various sampling, say) produces a different model.\n",
    "\n",
    "We can choose the best model using any criteria including AUC (area under the curve).\n",
    "Remember each model produces a different ROC curve.\n",
    "\n",
    "Once a model is chosen. You can walk along the ROC curve and pick any point on it.\n",
    "Each point has different precision/recall values.\n",
    "\n",
    "### Modeling Approaches: Weighting and Stratified Sampling\n",
    "\n",
    "In this section, we will cover:\n",
    "- Additional approaches to dealing with unbalanced outcomes\n",
    "- Random and Synthetic Over Sampling\n",
    "- Techniques for Under Sampling\n",
    "- Using Balanced Bagging (Bagging) to address unbalanced class data\n",
    "\n",
    "Lots of Approaches\n",
    "- General sklearn approaches\n",
    "- Oversampling\n",
    "- Undersampling\n",
    "- Combination\n",
    "- Ensembles\n",
    "- Check out http://contrib.scikit-learn.org/imbalanced-learn\n",
    "\n",
    "Weighting\n",
    "- Many models allow weighted observations\n",
    "- Adjust these so total weights are equal across classes\n",
    "- Easy to do, when it's available\n",
    "- No need to sacrifice data \n",
    "\n",
    "Stratified Sampling\n",
    "- Train-test split, \"stratify\" option\n",
    "- ShuffleSplit -> StratifiedShuffleSplit\n",
    "- KFold -> StratifiedKFold -> RepeatedStratifiedKFold\n",
    "\n",
    "### Modeling Approaches: Random and Synthetic Oversampling\n",
    "\n",
    "Random Oversampling\n",
    "- Simplest oversampling approach\n",
    "- Resample with replacement from minority class\n",
    "- No concerns about geometry of feature space\n",
    "- Good for categorical data\n",
    "\n",
    "![](./images/77_SyntheticOverSampling.png)\n",
    "\n",
    "#### Synthetic Oversampling\n",
    "- Start with a point in the minority class\n",
    "- Choose one of K nearest neighbors\n",
    "- Add a new point between them\n",
    "- Two main approaches:\n",
    "  - SMOTE : Synthetic Minority Oversampling Technique\n",
    "    - Regular: Connect minority class points to any neighbor (even other classes)\n",
    "    - Borderline: Classify points as outlier, safe, or in-danger\n",
    "      - 1: Connect minority in-danger points only to minority points\n",
    "      - 2: Connect minority in-danger points to whatever is nearby\n",
    "    - SVM: Use minority support vectors to generate new points\n",
    "  - ADASYN : ADAptive SYNthetic sampling\n",
    "    - For each minority point:\n",
    "      - Look at classes in neighborhood\n",
    "      - Generate new samples proportional to competing classes\n",
    "    - Motivated by KNN, but helps other classifiers as well\n",
    "\n",
    "### Modeling Approaches: Nearing Neighbor Methods\n",
    "\n",
    "In this section, we're going to focus on the idea of UNDERSAMPLING. Now, the concept here is going to be to try and decrease the size of that majority class so that it is similar in size to that minority class.\n",
    "\n",
    "![](./images/78_NearMiss1.png)\n",
    "\n",
    "![](./images/78_NearMiss2.png)\n",
    "\n",
    "![](./images/78_NearMiss3.png)\n",
    "\n",
    "![](./images/81_TomekLinks.png)\n",
    "\n",
    "![](./images/82_EditedNearestNeighbors.png)\n",
    "\n",
    "### Modeling Approaches: Blagging\n",
    "\n",
    "Combination Over/Under\n",
    "- SMOTE + Tomek's link\n",
    "- SMOTE + Edited Nearest Neighbors\n",
    "\n",
    "![](./images/83_BalancedBagging.png)\n",
    "\n",
    "#### Unbalanced Classes: Summary\n",
    "\n",
    "All of this happens after the test set has been split.\n",
    "\n",
    "Use sensible metrics\n",
    "- AUC\n",
    "- F1\n",
    "- Cohen's Kappa\n",
    "- Not accuracy - too easy to fool in this case\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary/Review\n",
    "\n",
    "## Modeling Unbalanced Classes\n",
    "\n",
    "Classification algorithms are built to optimize accuracy, which makes it challenging to create a model when there is not a balance across the number of observations of different classes. Common methods to approach balancing the classes are:\n",
    "\n",
    "- Downsampling or removing observations from the most common class\n",
    "\n",
    "- Upsampling or duplicating observations from the rarest class or classes\n",
    "\n",
    "- A mix of downsampling and upsampling\n",
    "\n",
    "## Modeling Approaches for Unbalanced Classes\n",
    "\n",
    "Specific algorithms to upsample and downsample are:\n",
    "\n",
    "- Stratified sampling\n",
    "\n",
    "- Random oversampling\n",
    "\n",
    "- Synthetic oversampling, the main two approaches being Synthetic Minority Oversampling Technique (SMOTE) and Adaptive Synthetic sampling (ADASYN)\n",
    "\n",
    "- Cluster Centroids implementations like NearMiss, Tomek Links, and Nearest Neighbors  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
