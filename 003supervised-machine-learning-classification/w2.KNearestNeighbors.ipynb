{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest neighbors\n",
    "\n",
    "K Nearest Neighbors is a popular classification method because they are easy computation and easy to interpret. This module walks you through the theory behind k nearest neighbors as well as a demo for you to practice building k nearest neighbors models with sklearn.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Identify common supervised machine learning algorithms.\n",
    "\n",
    "- Identify, use, and interpret k nearest neighbors models for classification\n",
    "\n",
    "- Build k nearest neighbors models with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors for Classification\n",
    "\n",
    "### Learning Goals\n",
    "In this section, we will cover:\n",
    "- The K Nearest Neighbors (KNN) approach for Classification\n",
    "- The KNN decision boundary\n",
    "- Distance measurement and the importance of Feature Scaling\n",
    "- Implementation of KNN for both Classification and Regression\n",
    "\n",
    "\n",
    "\n",
    "## K Nearest Neighbors Decision Boundary\n",
    "![](./images/12_KNearestNeighborsDecisionboundary.png)\n",
    "![](./images/13_KNNElbowCurve.png)\n",
    "\n",
    "## K Nearest Neighbors Distance Measurement\n",
    "![](./images/14_EuclideanDistance.png)\n",
    "\n",
    "![](./images/15_ManhattanDistance.png)\n",
    "\n",
    "![](./images/16_ScaleForDistanceMeasurement.png)\n",
    "\n",
    "![](./images/17_FeatureScaling.png)\n",
    "\n",
    "![](./images/18_KNNDecisionBoundary.png)\n",
    "\n",
    "\n",
    "### KNN Regression: mean of K nearest\n",
    "![](./images/19_KNNRegression.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## K Nearest Neighbors Pros and Cons\n",
    "\n",
    "Pros:\n",
    "- Simple to implement (does not require estimation)\n",
    "- Adapts well as new training data\n",
    "- Easy to interpret\n",
    "\n",
    "Cons:\n",
    "- Slow to predict because many distance calculations\n",
    "- Does not generate insight into data generating process (no model)\n",
    "- Can require lots of memory if data set is large (or as it grows)\n",
    "- When there are many predictors, KNN accuracy can break down due to\n",
    "curse of dimensionality\n",
    "\n",
    "## K Nearest Neighbors with Feature Scaling\n",
    "\n",
    "![](./images/20_KNNvsLinearRegression.png)\n",
    "\n",
    "### K Nearest Neighbors: The Syntax\n",
    "\n",
    "```python\n",
    "# Import the class containing the classification method\n",
    "from sklearn. neighbors import KNeighborsClassifier\n",
    "# Create an instance of the class\n",
    "KNeighborsClassifier (n neighbors=3)\n",
    "# Fit the instance on the data and then predict the expected value\n",
    "KNN = KNN. fit (X_train, _train)\n",
    "y_predict = KNN. predict (X test)\n",
    "```\n",
    "\n",
    "The fit and predict/transform syntax will show up throughout the course.\n",
    "\n",
    "## K Nearest Neighbors\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
