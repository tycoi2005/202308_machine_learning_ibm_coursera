{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "In this module you become familiar with Autoencoders, an useful application of Deep Learning for Unsupervised Learning. Autoencoders are a neural network architecture that forces the learning of a lower dimensional representation of data, commonly images. In this module you will learn some Deep learning-based techniques for data representation, how autoencoders work, and to describe the use of trained autoencoders for image applications\n",
    "\n",
    "Learning Objectives\n",
    "- Explain the theory behind autoencoders\n",
    "- Gain understanding on best practices for developing Autoencoders\n",
    "- Gain practice using Keras and sklearn for Autoencoders applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Autoencoders\n",
    "\n",
    "In this section, we will cover:\n",
    "- Non-Deep learning-based techniques for data representation \n",
    "- How autoencoders work\n",
    "- How to describe the use of trained autoencoders to generate\n",
    "images\n",
    "\n",
    "Autoencoders: Overview\n",
    "Autoencoders are a type of unsupervised deep learning model that use to  hidden layers \n",
    "decompose and then recreate their input. They have several applications:\n",
    "- Dimensionality reduction\n",
    "- Preprocessing for classification\n",
    "- Identifying 'essential' elements of the input data, and filtering out noise\n",
    "\n",
    "## Autoencoders\n",
    "\n",
    "\n",
    "# Summary/Review\n",
    "\n",
    "## Autoencoders\n",
    "\n",
    "Autoencoders are a neural network architecture that forces the learning of a lower dimensional representation of data, commonly images.\n",
    "\n",
    "Autoencoders are a type of unsupervised deep learning model that use hidden layers to decompose and then recreate their input. They have several applications:\n",
    "\n",
    "- Dimensionality reduction \n",
    "\n",
    "- Preprocessing for classification\n",
    "\n",
    "- Identifying ‘essential’ elements of the input data, and filtering out noise\n",
    "\n",
    "One of the main motivations is find whether two pictures are similar.\n",
    "\n",
    "\n",
    "## Autoencoders and PCA\n",
    "\n",
    "Autoencoders can be used in cases that are suited for Principal Component Analysis (PCA).\n",
    "\n",
    "Autoencoders also help to deal with some of these PCA limitations: PCA has learned features that are linear combinations of original features.\n",
    "\n",
    "Autoencoders can detect complex, nonlinear relationship between original features and best lower dimensional representation.\n",
    "\n",
    "\n",
    "## Autoencoding process\n",
    "\n",
    "The process for autoencoding can be summarized as:\n",
    "\n",
    "1. Feed image through encoder network\n",
    "\n",
    "2. Generate the lower dimension embedding\n",
    "\n",
    "3. Feed embedding through decoder network\n",
    "\n",
    "4. Generate reconstructed version of the original data\n",
    "\n",
    "5. Compare the result of the generated vs the original image\n",
    "\n",
    "Result: A network will learn the lower dimensional space that represents the original data\n",
    "\n",
    "\n",
    "## Autoencoder applications\n",
    "\n",
    "Autoencoders have a wide variety of enterprise applications:\n",
    "\n",
    "- Dimensionality reduction as preprocessing for classification\n",
    "\n",
    "- Information retrieval\n",
    "\n",
    "- Anomaly detection\n",
    "\n",
    "- Machine translation\n",
    "\n",
    "- Image-related applications (generation, denoising, processing and compression)\n",
    "\n",
    "- Drug discovery\n",
    "\n",
    "- Popularity prediction for social media posts\n",
    "\n",
    "- Sound and music synthesis\n",
    "\n",
    "- Recommender systems\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
