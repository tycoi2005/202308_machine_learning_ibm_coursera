{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Optimizers\n",
    "\n",
    "You can leverage several options to prioritize the training time or the accuracy of your neural network and deep learning models. In this module you learn about key concepts that intervene during model training, including optimizers and data shuffling. You will also gain hands-on practice using Keras, one of the go-to libraries for deep learning. \n",
    "\n",
    "Learning Objectives\n",
    "- Understand Neural Networks as the main unit for Deep Learning\n",
    "- Become familiarized with solution optimizers used in Neural Networks, including gradient descent and data shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers and Data Shuffling\n",
    "\n",
    "## Optimizers and Momentum\n",
    "\n",
    "### Optimizers\n",
    "We have considered approaches to gradient descent\n",
    "that vary the number of data points involved in a step.\n",
    "\n",
    "However, they have all used the standard update formula:\n",
    "\n",
    "$$\n",
    "W := W - \\alpha • \\Delta J\n",
    "$$\n",
    "\n",
    "There are several variants to updating the weights which give better performance in practice.\n",
    "\n",
    "These successive \"tweaks\" each attempt to improve on the previous idea.\n",
    "\n",
    "The resulting (often complicated) methods are referred to as \"optimizers\".\n",
    "\n",
    "### Momentum\n",
    "\n",
    "Idea, only change direction by a little bit each time.\n",
    "\n",
    "Keeps a \"running average\" of the step directions, smoothing out the variation of the individual points.\n",
    "\n",
    "$V_t := \\eta • V_{t-1} - \\alpha • \\delta V$\n",
    "$W := W - V_t$\n",
    "\n",
    "Here, $\\eta$ is referred to as the \"momentum\".\n",
    "It is generally given a value <1\n",
    "\n",
    "![](./images/16_Momentum.png)\n",
    "\n",
    "#### Nesterov Momentum\n",
    "\n",
    "Idea: control \"overshooting\" by looking ahead.\n",
    "\n",
    "Apply gradient only to the \"non-momentum\" component.\n",
    "\n",
    "\n",
    "$v_t = \\eta • v_{t-1} - \\alpha • \\Delta(J - \\eta • v_{t-1})$\n",
    "\n",
    "$W== W - v_t$\n",
    "\n",
    "\n",
    "![](./images/17_NesterovMomentum.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Popular Optimizers\n",
    "\n",
    "### AdaGrad\n",
    "\n",
    "Idea: scale the update for each weight separately.\n",
    "1. Update frequently-updated weights less.\n",
    "2. Keep running sum of previous updates.\n",
    "3. Divide new updates by factor of previous sum.\n",
    "\n",
    "With starting point $G_i(0) = 0:\n",
    "\n",
    "$ G_i(t) = G_i(t - 1) + (\\dfrac{\\delta L}{\\delta w_i} (t)^2 $  -> G will continue to increase\n",
    "\n",
    "\n",
    "$W:=W-\\dfrac{\\eta}{\\sqrt G_t+\\epsilon}.\\Delta J$ -> This leads to smaller updates each iteration\n",
    "\n",
    "### RMSProp \n",
    "\n",
    "Quite similar to AdaGrad.\n",
    "- Rather than using the sum of previous gradients,\n",
    "decay older gradients more than more recent ones.\n",
    "- More adaptive to recent updates.\n",
    "\n",
    "![](./images/18_AdamOptimizer.png)\n",
    "\n",
    "### Which Should You Use?\n",
    "\n",
    "RMSProp and Adam seem to be quite popular. From 2012 to 2017, approximately 23% of\n",
    "deep learning papers submitted to arXiv (a popular platform for research in Deep Learning)\n",
    "mentioned using the Adam approach.\n",
    "\n",
    "It can be difficult to predict in advance which will be best for a particular problem.\n",
    "\n",
    "This is still an active area of inquiry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Details of Training Neural Networks\n",
    "\n",
    "Learning Goals\n",
    "- Details of training Neural Network models\n",
    "- Stochastic gradient descent\n",
    "- Batching approaches and terminology\n",
    "\n",
    "Given an example (or group of examples),\n",
    "we know how to compute the derivative for each weight.\n",
    "1. How exactly do we update the weights?\n",
    "2. How often? (..after each training data point? ..after all the training data points?)\n",
    "\n",
    "### What Next? - Gradient Descent\n",
    "\n",
    "Classical approach: get derivative for entire data set, then take a step in that direction.\n",
    "- Pros: Each step is informed by all the data.\n",
    "- Cons: Very slow, especially as data gets big.\n",
    "\n",
    "$W_new = W_old - lr* derivative$\n",
    "\n",
    "### Stochastic Gradient Descent\n",
    "\n",
    "Get derivative for just one point, and take a step in that direction.\n",
    "- Steps are \"less informed\", but you\n",
    "take more of them.\n",
    "- Should \"balance out\".\n",
    "- Probably want a smaller step size.\n",
    "- Also helps \"regularize\".\n",
    "\n",
    "### Compromise Approach: Mini-batch\n",
    "\n",
    "Get derivative for a \"small\" set of points, then take a step in that direction.\n",
    "- Typical mini batch sizes are 16, 32.\n",
    "- Strikes a balance between two extremes.\n",
    "\n",
    "![](./images/19_ComparisonOfBatchingApproaches.png)\n",
    "\n",
    "#### Batching Terminology\n",
    "\n",
    "- Full-batch: Use entire data set to compute gradient before updating.\n",
    "- Mini-batch: Use a smaller portion of data (but more than single example)\n",
    "to compute gradient before updating.\n",
    "- Stochastic Gradient Descent (SGD): Use a single example to compute gradient\n",
    "before updating (though sometimes people use SGD to refer to minibatch, also).\n",
    "\n",
    "- An Epoch: refers to a single pass through all of the training data.\n",
    "  - In full batch gradient descent, there would be one step taken per epoch.\n",
    "  - In SGD / Online learning, there would be n steps taken per epoch (n = training set size).\n",
    "  - In Minibatch there would be (n / batch size) steps taken per epoch.\n",
    "- When training, we often refer to the number of epochs needed for the model to be \"trained\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Shuffling\n",
    "\n",
    "Note on Data Shuffling\n",
    "\n",
    "To avoid any cyclical movement and aid convergence,\n",
    "it is recommended to shuffle the data after each epoch.\n",
    "\n",
    "This way,\n",
    "the data is not seen in the same order every time,\n",
    "and the batches are not the exact same ones.\n",
    "\n",
    "![](./images/20_TrainingInAction.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Transforms\n",
    "\n",
    "### Scaling Inputs\n",
    "\n",
    "In our discussion of backpropagation we briefly touched on the formula\n",
    "for the gradient used to update the values of our weights W:\n",
    "\n",
    "$\\dfrac{\\delta J}{\\delta W^{(i)}} = (\\hat y - y) • a^{(i)}$\n",
    "\n",
    "And at each iteration of gradient Descent:\n",
    "$ W_{new} = W_{old} - lr * derivative$\n",
    "\n",
    "When i = 0, we are using the input values X as part of derivative to update $W_{new}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that if we do not normalize the input values,\n",
    "those with higher values will update much more quickly than those with lower values.\n",
    "\n",
    "This imbalance can greatly slow down the speed at which our model converges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ways to Scale Inputs\n",
    "Linear scaling to the interval [0,1]:\n",
    "\n",
    "$x_i=\\dfrac{x_i-x_{min}}{x_{max}-x_{min}}$\n",
    "\n",
    "Linear scaling to the interval [-1,1]:\n",
    "\n",
    "$x_i=2(\\dfrac{x_i-x_{min}}{x_{max}-x{min}})-1$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
