{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to neural network\n",
    "\n",
    "This module introduces Deep Learning, Neural Networks, and their applications. You will go through the theoretical background and characteristics that they share with other machine learning algorithms, as well as characteristics that make them stand out as great modeling techniques for specific scenarios. You will  also gain some hands-on practice on Neural Networks and key concepts that help these algorithms converge to robust solutions.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "Explain the kinds of problems suitable for Neural Networks and Deep Learning\n",
    "\n",
    "Describe the main components of a neural network\n",
    "\n",
    "Describe the steps in building a Neural Network model\n",
    "\n",
    "Become familiar with neural networks in Keras and Scikit learn\n",
    "\n",
    "Practice using Keras library for Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Course Introduction\n",
    "\n",
    "## Introduction to Neural Networks\n",
    "\n",
    "Background on Neural Networks\n",
    "- Use biology as inspiration for mathematical models\n",
    "- Get signals from previous neurons\n",
    "- Generate signals (or not) according to inputs\n",
    "- Pass signals on to next neurons\n",
    "- By layering many neurons, can create complex model\n",
    "\n",
    "Neural Net Structure\n",
    "- Can think of it as a complicated computation engine\n",
    "- We will \"train it\" using our training data\n",
    "- Then use it to generate predictions using new data\n",
    "\n",
    "\n",
    "## Basics of Neurons\n",
    "\n",
    "![](./images/01_BasicNeuronVisulaization.png)\n",
    "\n",
    "![](./images/02_BasicNeuronVisulaization.png)\n",
    "\n",
    "In Vector Notation\n",
    "- z \"net input\"\n",
    "- b = \"bias term\"\n",
    "- f = activation function\n",
    "- a = output to next layer\n",
    "\n",
    "Relation to Logistic Regression\n",
    "\n",
    "When we choose $ f(Z) = \\dfrac{1}{1+e^{-z}}$\n",
    "\n",
    "$$\n",
    "z = b + \\sum_{i=1}^m x_iw_i = x_1w_1 + x_2w_2+....+x_mw_m+b\n",
    "$$\n",
    "\n",
    "Then a neuron is simply a \"unit\" of logistic regression.\n",
    "\n",
    "weights + coefficients, inputs + variables, bias term + constant term\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nice Property of Sigmoid Function\n",
    "\n",
    "![](./images/03_SigmoidFunction.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\sigma(z)= \\dfrac{1}{1+e^{-z}} $ Quotient rule: $\\dfrac{d}{dx}.\\dfrac{f(x)}{g(x)}=\\dfrac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\sigma{'}(z) = \\dfrac{0-(-e^{-z})}{(1+e^{-z})^2} = \\dfrac{e^{-z}}{(1+e^{-z})^2} = \\dfrac{1+e^{-z}-1}{(1+e^{-z})^2} = \\dfrac{1+e^{-z}}{(1+e^{-z})^2} - \\dfrac{1}{{(1+e^{-z})^2}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\sigma{'}(z) = \\dfrac{1}{{1+e^{-z}}} - \\dfrac{1}{{(1+e^{-z})^2}} = \\dfrac{1}{{1+e^{-z}}} (1 - \\dfrac{1}{{1+e^{-z}}})\n",
    "$\n",
    "\n",
    "$\n",
    "\\sigma{'}(z) = \\sigma(z)(1-\\sigma(z)) \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron in Action\n",
    "\n",
    "### Example Neuron Computation\n",
    "![](./images/04_ExampleOfNeuronCaculation.png)\n",
    "\n",
    "Why Neural Networks?\n",
    "\n",
    "Why not just use a single neuron? Why do we need a larger network?\n",
    "\n",
    "A single neuron (like logistic regression) only permits a linear decision boundary.\n",
    "\n",
    "Most real-world problems are considerably more complicated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/cdp/cf/ul/g/3a/b8/ICLH_Diagram_Batch_01_03-DeepNeuralNetwork.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Neural Networks with SKlearn\n",
    "\n",
    "Multi-Layer Perceptron Syntax (Scikit-Learn)\n",
    "```python\n",
    "# Import Scikit-Learn model\n",
    "from sklearn.neural network import MLPClassifier\n",
    "\n",
    "# Specify an activation function\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5,2), activation= 'logistic')\n",
    "\n",
    "# Fit and predict data (similar to approach for other sklearn models)\n",
    "mlp. fit (X_train, y train)\n",
    "mlp.predict (X test)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "\n",
    "## Matrix Representation of Forward Propagation\n",
    "\n",
    "## Main Types of Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization and Gradient Descent\n",
    "\n",
    "## Gradient Descent Basics\n",
    "\n",
    "## Compare Different Gradient Descent Methods\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
