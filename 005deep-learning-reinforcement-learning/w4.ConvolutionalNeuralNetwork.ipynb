{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "In this module you become familiar with convolutional neural networks, also known as space invariant artificial neural networks, a type of deep neural networks, frequently used in image AI applications. There are several CNN architectures, you will learn some of the most common ones to add to your toolkit of Deep Learning Techniques.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "Explain how a Convolutional Neural Network works\n",
    "\n",
    "Become familiar with the most common architectures for Convolutional Neural Networks\n",
    "\n",
    "Gain practice using CNNs for classification and image applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Cross Entropy\n",
    "\n",
    "Multiclass Classification with Neural Networks\n",
    "\n",
    "For binary classification problems, we have a final layer\n",
    "with a single node and a sigmoid activation.\n",
    "\n",
    "This has many desirable properties:\n",
    "- Gives an output strictly between 0 and r\n",
    "- Can be interpreted as a probability\n",
    "- Derivative is \"nice\"\n",
    "- Analogous to logistic regression\n",
    "\n",
    "Is there a natural extension of this to a multiclass setting?\n",
    "\n",
    "Reminder: one hot encoding for categories.\n",
    "1. Take a vector with length equal to the number of categories.\n",
    "2. Represent each category with one (1) at a particular position and zero (0) everywhere else. For\n",
    "example, we can represent types of bank account types:\n",
    "\n",
    "![](./images/21_BankExampleOneHotEncoding.png)\n",
    "\n",
    "\n",
    "For multiclass classification problems, let the final layer be\n",
    "a vector with length equal to the number of possible classes.\n",
    "\n",
    "Extension of sigmoid to multiclass is the **softmax** function.\n",
    "\n",
    "$$\n",
    "softmax(z_i)= \\dfrac{e^{z_i}}{\\sum_{k=1}^K e^{z_k}}\n",
    "$$\n",
    "\n",
    "Yields a vector with entries that are between 0 and 1, and sum to 1.\n",
    "\n",
    "\n",
    "For loss function use \"categorical cross entropy\".\n",
    "\n",
    "This is just the log-loss function in disguise:\n",
    "\n",
    "$$\n",
    "C.E.E. = - \\sum_{i=1}^n y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "Derivative has a nice property when used with softmax:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C.E.}{\\partial \\text{softmax}} . \\frac{\\partial \\text{softmax}}{\\partial z_i} = \\hat{y}_i - y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Convolutional Neural Networks (CNN)\n",
    "\n",
    "## Motivation - Image Data\n",
    "\n",
    "So far, the structure of our neural network treats all inputs interchangeably.\n",
    "\n",
    "No relationships between the individual inputs.\n",
    "\n",
    "Just an ordered set of variables.\n",
    "\n",
    "We want to incorporate domain knowledge into the architecture of a Neural Network.\n",
    "\n",
    "The convolutional networks we discuss here were developed to deal with image data.\n",
    "\n",
    "Increasingly, these approaches are being applied in more common analytic problems of\n",
    "regression and classification.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Important structures in image data:\n",
    "- \"Topology\" of pixels\n",
    "- Translation invariance\n",
    "- Issues of lighting and contrast\n",
    "- Knowledge of human visual system\n",
    "- pixels tend to have similar values\n",
    "- Edges and shapes\n",
    "- Scale Invariance (a big cat has similar adj with a small cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images Dataset\n",
    "\n",
    "Motivation - Image Data\n",
    "\n",
    "Fully connected image networks would require a vast number\n",
    "of parameters.\n",
    "\n",
    "MNIST images are small (28 x 28 pixels), and in grayscale\n",
    "Color images typically contain:\n",
    "[(200 X 200) pixels] x [3 color channels (RGB)] =\n",
    "120,000 values (features).\n",
    "\n",
    "A single fully connected layer would require:\n",
    "(200 * 200 x 3)2 = 14,400,000,000 weights!\n",
    "- Variance (in terms of bias-variance) would be too high.\n",
    "- So we introduce \"bias\" by structuring the network to look for certain kinds of patterns.\n",
    "\n",
    "Features need to be \"built up\".\n",
    "- Edges shapes  relations between shapes\n",
    "- Textures\n",
    "\n",
    "Example: Cat = [two eyes in certain relation to one another] + [cat fur texture].\n",
    "- Eyes = dark circle (pupil) inside another circle.\n",
    "- Circle = particular combination of edge detectors.\n",
    "- Fur = edges in certain pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Kernels\n",
    "\n",
    "A kernel is a grid of weights \"overlaid\" on image, centered on one pixel.\n",
    "- Each weight multiplied with pixel underneath it.\n",
    "- Output over the centered pixel is: $\\sum_{p=1}^PW_p . pixel_p$\n",
    "\n",
    "Used for traditional image processing techniques:\n",
    "- Blur, Sharpen, Edge detection, Emboss, etc.\n",
    "\n",
    "![](./images/22_Kernel.png)\n",
    "\n",
    "![](./images/23_KernelAsFeatureDetectors.png)\n",
    "\n",
    "### Convolutional Neural Nets\n",
    "\n",
    "Primary Ideas behind Convolutional Neural Networks:\n",
    "- Let the Neural Network learn which kernels are most useful.\n",
    "- Use same set of kernels across entire image (translation invariance).\n",
    "- Reduces number of parameters and \"variance\" (from bias-variance point of view).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution for Color Images\n",
    "\n",
    "Primary Ideas behind Convolutional Neural Networks:\n",
    "- Let the Neural Network learn which kernels are most useful.\n",
    "- Use same set of kernels across entire image (translation invariance).\n",
    "- Reduces number of parameters and \"variance\" (from bias-variance point of view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Convolutional Settings - Padding and Stride\n",
    "\n",
    "Convolution Settings - Grid Size\n",
    "\n",
    "Grid Size (Height and Width):\n",
    "- The number of pixels a kernel \"sees\" at once.\n",
    "- Typically use odd numbers so that there is a \"center\" pixel.\n",
    "- Kernel does not need to be square.\n",
    "\n",
    "![](./images/24_ConvolutionalGridSize.png)\n",
    "\n",
    "Convolution Settings - Padding\n",
    "\n",
    "- Using Kernels directly, there will be an \"edge effect\".\n",
    "- Pixels near the edge will not be used as \"center pixels\"\n",
    "since there are not enough surrounding pixels.\n",
    "- Padding adds extra pixels around the frame, so pixels from the original image\n",
    "become center pixels as the kernel moves across the image.\n",
    "- Added pixels are typically of value zero (zero-padding).\n",
    "\n",
    "Convolution Settings - Stride\n",
    "- The \"step size\" as the kernel moves across the image.\n",
    "- Can be different for vertical and horizontal steps (but usually is the same value).\n",
    "- When stride is greater than 1. it scales down the output dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Settings - Depth and Pooling\n",
    "\n",
    "Convolutional Settings - Depth\n",
    "\n",
    "In images, we often have multiple numbers associated with each pixel location.\n",
    "These numbers are referred to as \"channels\".\n",
    "- RGB image: 3 channels.\n",
    "- CMYK: 4 channels.\n",
    "\n",
    "The number of channels is referred to as the \"depth\".\n",
    "\n",
    "So, the kernel itself will have a \"depth\" the same size as the number of input channels.\n",
    "\n",
    "Example: a 5 Ã— 5 kernel on an RGB image.\n",
    "- There will be 5 x 5 x 3 = 75 weights.\n",
    "\n",
    "The output from the layer will also have a depth.\n",
    "- The networks typically train many different kernels.\n",
    "- Each kernel outputs a single number at each pixel location.\n",
    "- So, if there are 10 kernels in a layer, the output of that layer will have depth = 10.\n",
    "\n",
    "![](./images/25_FeatureMap.png)\n",
    "\n",
    "Pooling\n",
    "\n",
    "Idea: Reduce the image size by mapping a patch of pixels to a single value.\n",
    "- Shrinks the dimensions of the image.\n",
    "- Does not have parameters, though there are different types of pooling operations.\n",
    "\n",
    "![](./images/26_MaxPool.png)\n",
    "\n",
    "![](./images/27_AveragePool.png)\n",
    "\n",
    "# Learning Recap\n",
    "\n",
    "In this section, we discussed:\n",
    "- Convolutional Neural Networks\n",
    "- Original motivation (image data)\n",
    "- Convolution settings: grid size, padding, pooling, depth"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
