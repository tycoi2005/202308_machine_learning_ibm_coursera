{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "In this module you become familiar with convolutional neural networks, also known as space invariant artificial neural networks, a type of deep neural networks, frequently used in image AI applications. There are several CNN architectures, you will learn some of the most common ones to add to your toolkit of Deep Learning Techniques.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "Explain how a Convolutional Neural Network works\n",
    "\n",
    "Become familiar with the most common architectures for Convolutional Neural Networks\n",
    "\n",
    "Gain practice using CNNs for classification and image applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Cross Entropy\n",
    "\n",
    "Multiclass Classification with Neural Networks\n",
    "\n",
    "For binary classification problems, we have a final layer\n",
    "with a single node and a sigmoid activation.\n",
    "\n",
    "This has many desirable properties:\n",
    "- Gives an output strictly between 0 and r\n",
    "- Can be interpreted as a probability\n",
    "- Derivative is \"nice\"\n",
    "- Analogous to logistic regression\n",
    "\n",
    "Is there a natural extension of this to a multiclass setting?\n",
    "\n",
    "Reminder: one hot encoding for categories.\n",
    "1. Take a vector with length equal to the number of categories.\n",
    "2. Represent each category with one (1) at a particular position and zero (0) everywhere else. For\n",
    "example, we can represent types of bank account types:\n",
    "\n",
    "![](./images/21_BankExampleOneHotEncoding.png)\n",
    "\n",
    "\n",
    "For multiclass classification problems, let the final layer be\n",
    "a vector with length equal to the number of possible classes.\n",
    "\n",
    "Extension of sigmoid to multiclass is the **softmax** function.\n",
    "\n",
    "$$\n",
    "softmax(z_i)= \\dfrac{e^{z_i}}{\\sum_{k=1}^K e^{z_k}}\n",
    "$$\n",
    "\n",
    "Yields a vector with entries that are between 0 and 1, and sum to 1.\n",
    "\n",
    "\n",
    "For loss function use \"categorical cross entropy\".\n",
    "\n",
    "This is just the log-loss function in disguise:\n",
    "\n",
    "$$\n",
    "C.E.E. = - \\sum_{i=1}^n y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "Derivative has a nice property when used with softmax:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C.E.}{\\partial \\text{softmax}} . \\frac{\\partial \\text{softmax}}{\\partial z_i} = \\hat{y}_i - y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Convolutional Neural Networks (CNN)\n",
    "\n",
    "\n",
    "# Images Dataset\n",
    "\n",
    "# Kernels\n",
    "\n",
    "# Convolution for Color Images\n",
    "\n",
    "# Convolutional Settings - Padding and Stride\n",
    "\n",
    "# Convolutional Settings - Depth and Pooling"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
