{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "This module introduces matrix factorization, which is a powerful technique for big data, text mining, and pre-processing data.\n",
    "\n",
    "Learning Objectives\n",
    "- Become familiar with the scikit learn syntax for Non Negative Matrix Factorization\n",
    "- Explain non negative matrix factorization, and how it makes PCA difficult with many features\n",
    "\n",
    "## Non Negative Matrix Factorization\n",
    "\n",
    "![](./images/27_NonNegativeMatrixFactorization.png)\n",
    "\n",
    "### Why Only Positive Values?\n",
    "Since NMF can never undo the application of a latent feature,\n",
    "it is much more careful about what it adds at each step.\n",
    "\n",
    "In some applications, this can make for more human interpretable latent features.\n",
    "\n",
    "Because NMF has the extra constraint of positive values,\n",
    "it will tend to lose more information when truncating.\n",
    "\n",
    "Also, NMF does not have to give orthogonal latent vectors.\n",
    "\n",
    "\n",
    "### NMF Summary\n",
    "Input:\n",
    "- Count Vectorizer or TF-IDF Vectorizer\n",
    "\n",
    "Parameters to Tune:\n",
    "- Number of Topics\n",
    "- Text Preprocessing (stop words, min / max doc freq, parts of speech...)\n",
    "\n",
    "Output:\n",
    "- W Matrix (terms topics) and H Matrix (documents -> topics)\n",
    "\n",
    "### NMF: the Syntax\n",
    "Import the class containing the clustering method.\n",
    "```python\n",
    "from sklearn.decomposition import NMF \n",
    "```\n",
    "Create an instance of the class.\n",
    "```python\n",
    "nmf = NMF(n_components=3, init=\"random\")\n",
    "```\n",
    "Fit the instance and create transformed version of the data:\n",
    "\n",
    "```python\n",
    "X_nmf = nmf.fit(X)\n",
    "```\n",
    "\n",
    "## Dimensionality Reduction: Approaches\n",
    "\n",
    "Dimensionality reduction is common across a wide range of applications\n",
    "Some rules of thumb for selecting an approach:\n",
    "\n",
    "| Method                              | Use case                                                                                                                             |\n",
    "|-------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Principal Components Analysis (PCA) | Identify small number of transformed variables with different effects, preserving variance                                           |\n",
    "| Kernel PCA                          | Useful for situations with nonlinear relationships, but requires more computation than PCA                                           |\n",
    "| Multidimensional Scaling            | Like PCA, but new (transformed features) are determined based on preserving distance between points, rather than explaining variance |\n",
    "| Non-negative Matrix Factorization   | Useful when you want to consider only positive values (word matrices, images)                                                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
