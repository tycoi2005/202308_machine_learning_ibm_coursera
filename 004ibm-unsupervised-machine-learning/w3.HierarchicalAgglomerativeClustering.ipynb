{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common clustering algorithms\n",
    "\n",
    "### Hierarchical Agglomerative Clustering\n",
    "\n",
    "steps:\n",
    "- we start off by looking at the points, and identifying the pair which has the minimal distance.\n",
    "- then we continue to do this, again, looking for the next closest pair of points and the next closest pair.\n",
    "- if it's a pair of clusters, if we do find it's a cluster that is the closest point, then we can go ahead and merge them into their own cluster.\n",
    "\n",
    "![](./images/07_hierarchicalAggo.png)\n",
    "\n",
    "how do we go about actually finding our stopping point? last n - clusters\n",
    "\n",
    "\n",
    "\n",
    "### Hierarchical Agglomerative Clustering: Hierarchical Linkage Types\n",
    "\n",
    "\n",
    "![](./images/08_hierachicalAgglomerativeClustering.png)\n",
    "\n",
    "![](./images/09_Singlelinkage.png)\n",
    "\n",
    "![](./images/10_CompleteLinkage.png)\n",
    "\n",
    "![](./images/11_AverageLinkage.png)\n",
    "\n",
    "![](./images/12_WardLinkage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Hierarchical Agglomerative Clustering\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Create an instance of the class.\n",
    "agg = AgglomerativeClustering (n_clusters=3,\n",
    "        affinity='euclidean', # distance metric choice\n",
    "        linkage='ward') # linkage: cluster aggregation\n",
    "\n",
    "# Fit the instance on the data and then predict clusters for new data.\n",
    "agg = agg.fit(X1)\n",
    "y_predict = agg predict(X2)\n",
    "\n",
    "```\n",
    "\n",
    "### DBSCAN\n",
    "\n",
    "Density-Based Spatial Clustering of Applications with Noise (DBSCAN)\n",
    "\n",
    "A true clustering algorithm:\n",
    "- can have points that don't belong to any cluster\n",
    "\n",
    "Points are clustered using density of local neighborhood:\n",
    "- finds core points in high density regions and expands clusters from them\n",
    "\n",
    "Algorithm ends when all points have been classified as either belonging to a cluster or to noise.\n",
    "\n",
    "\n",
    "Required inputs:\n",
    "- Metric: function to calculate distance\n",
    "- Epsilon (eps, E): radius of local neighborhood\n",
    "- N_ clu: determines density threshold (for fixed E)\n",
    "\n",
    "Core points are those which have more than n_clu neighbors in their local neighborhood (\"-neighborhood\").\n",
    "\n",
    "\n",
    "DBSCAN - Outputs : Three possible labels for any point:\n",
    "- Core:\n",
    "  - point which has more than n_clu neighbors in their &-neighborhood\n",
    "- Density-reachable:\n",
    "  - an &-neighbor of a core point than has fewer than n_clu neighbors itself\n",
    "- Noise:\n",
    "  - a point that has no core points in its &-neighborhood\n",
    "- Clusters:\n",
    "  - connected core and density-reachable points\n",
    "\n",
    "\n",
    "### Visualizing DBSCAN\n",
    "\n",
    "![](./images/13_dbscan.png)\n",
    "\n",
    "#### DBSCAN: Strengths and Weaknesses\n",
    "\n",
    "Strengths:\n",
    "- No need to specify number of clusters (cf. k-means)\n",
    "- Allows for noise\n",
    "- Can handle arbitrary-shaped clusters\n",
    "\n",
    "Weaknesses:\n",
    "- Requires two parameters (vs. one for k-means)\n",
    "- Finding appropriate values of & and n_clu can be difficult\n",
    "- Does not do well with clusters of different density\n",
    "\n",
    "\n",
    "#### DBSCAN: the Syntax\n",
    "```python\n",
    "#Import the class containing the clustering method.\n",
    "from sklearn. cluster import DBSCAN\n",
    "\n",
    "#Create an instance of the class.\n",
    "db = DBSCAN(eps=3, min_samples=2)\n",
    "\n",
    "#Fit the instance on the data and then predict clusters for new data.\n",
    "db = db.fit(X)\n",
    "clusters = db.labels_ # outliers assigned label = -1\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Shift\n",
    "\n",
    "A partitioning algorithm that assigns points to nearest cluster centroid.\n",
    "\n",
    "Centroid:\n",
    "- point of highest local density\n",
    "\n",
    "Algorithm ends when all points assigned to a cluster.\n",
    "\n",
    "![](./images/14_meanshift.png)\n",
    "\n",
    "#### Mean Shift: The Algorithm\n",
    "\n",
    "1. Choose a point and window W.\n",
    "\n",
    "2. Calculate weighted mean in W.\n",
    "\n",
    "3. Shift centroid of window to new mean.\n",
    "\n",
    "4. Repeat steps (2) and (3) until convergence (no shift)\n",
    "i.e. until local density maximum (\"mode\") is reached.\n",
    "\n",
    "5. Repeat steps (1-4) for all data points.\n",
    "\n",
    "6. Data points that lead to same mode are grouped into same cluster.\n",
    "\n",
    "![](./images/15_meanshiftvisual.png)\n",
    "\n",
    "![](./images/16_meanshift_weightedmean.png)\n",
    "\n",
    "#### Mean Shift: Strengths vs. Weaknesses\n",
    "\n",
    "Strengths:\n",
    "- Model-free: does not assume number or shape of clusters\n",
    "- Can use just one parameter: window size (bandwidth)\n",
    "- Robust to outliers\n",
    "\n",
    "Weaknesses:\n",
    "- Result depends on window size (bandwidth)\n",
    "- Selection of window size is not easy\n",
    "- Can be slow to implement, complexity proportional to mn? (for m iterations and n data points)\n",
    "\n",
    "\n",
    "#### Mean Shift: the Syntax\n",
    "\n",
    "```python\n",
    "# Import the class containing the clustering method.\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "# Create an instance of the class.\n",
    "ms = MeanShift(bandwidth=2)\n",
    "\n",
    "# Fit the instance on the data and then predict clusters for new data.\n",
    "ms.fit(X1)\n",
    "ms.predict(X2)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing clustering algorithms"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
